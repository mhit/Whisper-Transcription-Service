"""
ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡ºã¨Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ã‚’æä¾›ï¼š
- å‹•ç”»ã‹ã‚‰ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡º
- åˆ†æçµæœã®çµ±åˆ
- Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
"""

import logging
import json
import os
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
import math

try:
    import ffmpeg
except ImportError:
    print("ffmpeg-python ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install ffmpeg-python")
    ffmpeg = None

try:
    from PIL import Image
except ImportError:
    print("Pillow ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install Pillow")
    Image = None

from .utils import format_duration, format_filesize, safe_filename


class ReportGenerator:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆæœŸåŒ–

        Args:
            config: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆè¨­å®š
        """
        self.config = config
        self.logger = logging.getLogger('VideoTranscriptAnalyzer.reporter')

        # è¨­å®šå€¤
        self.format = config.get('format', 'markdown')
        self.include_screenshots = config.get('include_screenshots', True)
        self.screenshot_count = config.get('screenshot_count', 10)
        self.screenshot_width = config.get('screenshot_width', 800)
        self.screenshot_quality = config.get('screenshot_quality', 85)

    def extract_screenshots(self,
                          video_path: Path,
                          analysis_data: Optional[Dict[str, Any]],
                          output_dir: Path) -> List[Dict[str, Any]]:
        """
        å‹•ç”»ã‹ã‚‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’æŠ½å‡º

        Args:
            video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            analysis_data: åˆ†æãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç‰¹å®šç”¨ï¼‰
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

        Returns:
            ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæƒ…å ±ã®ãƒªã‚¹ãƒˆ

        Raises:
            RuntimeError: ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡ºå¤±æ•—
        """
        if not self.include_screenshots or not ffmpeg:
            self.logger.info("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return []

        if not video_path.exists():
            raise RuntimeError(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")

        self.logger.info(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡ºé–‹å§‹: {video_path}")

        try:
            # å‹•ç”»æƒ…å ±ã‚’å–å¾—
            probe = ffmpeg.probe(str(video_path))
            video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')
            duration = float(probe['format']['duration'])

            self.logger.info(f"å‹•ç”»æ™‚é–“: {format_duration(duration)}")

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            screenshots_dir = output_dir / "screenshots"
            screenshots_dir.mkdir(exist_ok=True)

            # æŠ½å‡ºã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ±ºå®š
            timestamps = self._determine_screenshot_timestamps(duration, analysis_data)

            screenshots = []
            for i, timestamp in enumerate(timestamps):
                screenshot_filename = f"screenshot_{i+1:02d}_{int(timestamp):04d}s.jpg"
                screenshot_path = screenshots_dir / screenshot_filename

                try:
                    # ffmpegã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡º
                    (
                        ffmpeg
                        .input(str(video_path), ss=timestamp)
                        .output(
                            str(screenshot_path),
                            vframes=1,
                            format='image2',
                            vcodec='mjpeg',
                            **{'q:v': 2}  # é«˜å“è³ª
                        )
                        .overwrite_output()
                        .run(capture_stdout=True, capture_stderr=True, quiet=True)
                    )

                    # ç”»åƒãƒªã‚µã‚¤ã‚ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                    if Image and self.screenshot_width:
                        self._resize_image(screenshot_path, self.screenshot_width)

                    # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæƒ…å ±ã‚’è¨˜éŒ²
                    screenshot_info = {
                        'index': i + 1,
                        'timestamp': timestamp,
                        'timestamp_formatted': format_duration(timestamp),
                        'filename': screenshot_filename,
                        'path': str(screenshot_path),
                        'relative_path': f"screenshots/{screenshot_filename}",
                        'size': screenshot_path.stat().st_size if screenshot_path.exists() else 0
                    }

                    # å¯¾å¿œã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
                    if analysis_data and 'segments' in analysis_data:
                        segment_text = self._find_segment_text(timestamp, analysis_data['segments'])
                        screenshot_info['segment_text'] = segment_text

                    screenshots.append(screenshot_info)
                    self.logger.debug(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆç”Ÿæˆ: {screenshot_filename}")

                except Exception as e:
                    self.logger.warning(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡ºå¤±æ•— ({timestamp}s): {e}")

            self.logger.info(f"âœ… {len(screenshots)} æšã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’æŠ½å‡º")
            return screenshots

        except Exception as e:
            error_msg = f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            raise RuntimeError(error_msg)

    def generate_report(self,
                       transcript_data: Optional[Dict[str, Any]],
                       analysis_data: Optional[Dict[str, Any]],
                       screenshots: List[Dict[str, Any]],
                       output_dir: Path) -> Path:
        """
        çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            transcript_data: æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿
            analysis_data: åˆ†æãƒ‡ãƒ¼ã‚¿
            screenshots: ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæƒ…å ±
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Raises:
            RuntimeError: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—
        """
        self.logger.info("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")

        try:
            # Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            if self.format == 'markdown' or self.format == 'both':
                markdown_path = self._generate_markdown_report(
                    transcript_data, analysis_data, screenshots, output_dir
                )

            # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if self.format == 'html' or self.format == 'both':
                html_path = self._generate_html_report(
                    transcript_data, analysis_data, screenshots, output_dir
                )

            # ãƒ¡ã‚¤ãƒ³ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ±ºå®š
            if self.format == 'html':
                return html_path
            else:
                return markdown_path

        except Exception as e:
            error_msg = f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            raise RuntimeError(error_msg)

    def _determine_screenshot_timestamps(self,
                                       duration: float,
                                       analysis_data: Optional[Dict[str, Any]]) -> List[float]:
        """
        ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæŠ½å‡ºã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ±ºå®š

        Args:
            duration: å‹•ç”»æ™‚é–“
            analysis_data: åˆ†æãƒ‡ãƒ¼ã‚¿

        Returns:
            ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒªã‚¹ãƒˆ
        """
        timestamps = []

        if analysis_data and 'segments' in analysis_data:
            # é‡è¦ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰é¸æŠ
            segments = analysis_data['segments']
            important_segments = []

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é‡è¦åº¦ã‚’è©•ä¾¡
            for segment in segments:
                # é•·ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã€é«˜ä¿¡é ¼åº¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é‡è¦ã¨ã¿ãªã™
                segment_length = segment.get('end', 0) - segment.get('start', 0)
                confidence = segment.get('confidence', 0.0)
                importance_score = segment_length * confidence

                important_segments.append({
                    'timestamp': segment.get('start', 0) + segment_length / 2,  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸­å¤®
                    'score': importance_score,
                    'start': segment.get('start', 0),
                    'end': segment.get('end', 0)
                })

            # é‡è¦åº¦é †ã§ã‚½ãƒ¼ãƒˆ
            important_segments.sort(key=lambda x: x['score'], reverse=True)

            # ä¸Šä½ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰é¸æŠï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
            min_interval = duration / (self.screenshot_count * 2)  # æœ€å°é–“éš”
            for segment in important_segments:
                timestamp = segment['timestamp']

                # æ—¢å­˜ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨é‡è¤‡ã—ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                if not any(abs(timestamp - existing) < min_interval for existing in timestamps):
                    timestamps.append(timestamp)

                if len(timestamps) >= self.screenshot_count:
                    break

        # ä¸è¶³åˆ†ã¯ç­‰é–“éš”ã§è£œå®Œ
        while len(timestamps) < self.screenshot_count:
            interval = duration / (self.screenshot_count + 1)
            for i in range(1, self.screenshot_count + 1):
                candidate = i * interval

                # æ—¢å­˜ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨é‡è¤‡ã—ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                if not any(abs(candidate - existing) < interval * 0.3 for existing in timestamps):
                    timestamps.append(candidate)

                if len(timestamps) >= self.screenshot_count:
                    break

        # ã‚½ãƒ¼ãƒˆã—ã¦è¿”ã™
        return sorted(timestamps[:self.screenshot_count])

    def _find_segment_text(self, timestamp: float, segments: List[Dict[str, Any]]) -> str:
        """
        ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¯¾å¿œã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—

        Args:
            timestamp: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            segments: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ

        Returns:
            å¯¾å¿œã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        for segment in segments:
            start = segment.get('start', 0)
            end = segment.get('end', 0)

            if start <= timestamp <= end:
                return segment.get('text', '').strip()

        # æœ€ã‚‚è¿‘ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ¢ã™
        closest_segment = min(
            segments,
            key=lambda s: min(
                abs(timestamp - s.get('start', 0)),
                abs(timestamp - s.get('end', 0))
            )
        )
        return closest_segment.get('text', '').strip()

    def _resize_image(self, image_path: Path, max_width: int) -> None:
        """
        ç”»åƒã‚’ãƒªã‚µã‚¤ã‚º

        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            max_width: æœ€å¤§å¹…
        """
        if not Image:
            return

        try:
            with Image.open(image_path) as img:
                # ç¾åœ¨ã®ã‚µã‚¤ã‚º
                width, height = img.size

                # ãƒªã‚µã‚¤ã‚ºãŒå¿…è¦ã‹åˆ¤å®š
                if width <= max_width:
                    return

                # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ä¿æŒã—ã¦ãƒªã‚µã‚¤ã‚º
                ratio = max_width / width
                new_width = max_width
                new_height = int(height * ratio)

                # ãƒªã‚µã‚¤ã‚ºå®Ÿè¡Œ
                resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                resized_img.save(image_path, quality=self.screenshot_quality, optimize=True)

                self.logger.debug(f"ç”»åƒãƒªã‚µã‚¤ã‚º: {width}x{height} -> {new_width}x{new_height}")

        except Exception as e:
            self.logger.warning(f"ç”»åƒãƒªã‚µã‚¤ã‚ºå¤±æ•— {image_path}: {e}")

    def _generate_markdown_report(self,
                                transcript_data: Optional[Dict[str, Any]],
                                analysis_data: Optional[Dict[str, Any]],
                                screenshots: List[Dict[str, Any]],
                                output_dir: Path) -> Path:
        """
        Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            transcript_data: æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿
            analysis_data: åˆ†æãƒ‡ãƒ¼ã‚¿
            screenshots: ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæƒ…å ±
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸMarkdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        report_path = output_dir / "video_analysis_report.md"

        with open(report_path, 'w', encoding='utf-8') as f:
            # ãƒ˜ãƒƒãƒ€ãƒ¼
            f.write("# å‹•ç”»åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")

            # æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            f.write("## ğŸ“Š æ¦‚è¦\n\n")
            if transcript_data:
                duration = transcript_data.get('duration', 0)
                segments_count = len(transcript_data.get('segments', []))
                f.write(f"- **å‹•ç”»æ™‚é–“**: {format_duration(duration)}\n")
                f.write(f"- **ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°**: {segments_count:,}å€‹\n")
                f.write(f"- **æ¤œå‡ºè¨€èª**: {transcript_data.get('language', 'ä¸æ˜')}\n")

            if analysis_data and analysis_data.get('metadata'):
                metadata = analysis_data['metadata']
                f.write(f"- **åˆ†ææ™‚é–“**: {metadata.get('analysis_time', 0):.1f}ç§’\n")
                f.write(f"- **ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: {metadata.get('model_used', 'ä¸æ˜')}\n")

            f.write(f"- **ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ•°**: {len(screenshots)}æš\n\n")

            # éšå±¤çš„è¦ç´„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if analysis_data and analysis_data.get('hierarchical_summaries'):
                hierarchical = analysis_data['hierarchical_summaries']

                # Level 3 - æœ€çµ‚çµ±åˆè¦ç´„
                if hierarchical.get('level3'):
                    f.write("## ğŸ“ çµ±åˆè¦ç´„\n\n")
                    f.write(f"{hierarchical['level3'].get('text', '')}\n\n")

                # Level 2 - ä¸­é–“è¦ç´„
                if hierarchical.get('level2'):
                    f.write("## ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦ç´„\n\n")
                    for i, summary in enumerate(hierarchical['level2'][:5], 1):
                        f.write(f"### ã‚°ãƒ«ãƒ¼ãƒ— {summary.get('group_id', i)}\n")
                        f.write(f"**æ™‚é–“ç¯„å›²**: {format_duration(summary.get('start_time', 0))} - {format_duration(summary.get('end_time', 0))}\n\n")
                        f.write(f"{summary.get('text', '')}\n\n")

                # é‡è¦ãªç¬é–“ï¼ˆéšå±¤çš„è¦ç´„ã‹ã‚‰ï¼‰
                if analysis_data.get('key_moments'):
                    f.write("## ğŸŒŸ é‡è¦ãªç¬é–“\n\n")
                    for i, moment in enumerate(analysis_data['key_moments'][:10], 1):
                        importance = moment.get('importance_score', 0)
                        importance_icon = 'ğŸ”´' if importance > 0.8 else 'ğŸŸ¡' if importance > 0.5 else 'ğŸŸ¢'
                        f.write(f"{i}. {importance_icon} **[{format_duration(moment.get('start_time', 0))}]** ")
                        f.write(f"(é‡è¦åº¦: {importance:.1%})\n")
                        f.write(f"   - {moment.get('preview', '')}\n")
                        f.write(f"   - ç†ç”±: {moment.get('reason', '')}\n\n")

            # é€šå¸¸ã®è¦ç´„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆéšå±¤çš„è¦ç´„ãŒãªã„å ´åˆï¼‰
            elif analysis_data and analysis_data.get('summary'):
                f.write("## ğŸ“ è¦ç´„\n\n")
                summary = analysis_data['summary'].get('main_summary', '')
                f.write(f"{summary}\n\n")

            # é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆéšå±¤çš„è¦ç´„ãŒãªã„å ´åˆï¼‰
            if analysis_data and analysis_data.get('key_points') and not analysis_data.get('hierarchical_summaries'):
                f.write("## ğŸ¯ é‡è¦ãƒã‚¤ãƒ³ãƒˆ\n\n")
                for i, point in enumerate(analysis_data['key_points'][:10], 1):
                    importance = point.get('importance', 'medium')
                    importance_icon = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(importance, 'âšª')
                    f.write(f"{i}. {importance_icon} {point.get('point', '') if isinstance(point, dict) else point}\n")
                    if isinstance(point, dict) and point.get('category'):
                        f.write(f"   - ã‚«ãƒ†ã‚´ãƒª: {point['category']}\n")
                f.write("\n")

            # ãƒˆãƒ”ãƒƒã‚¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            if analysis_data and analysis_data.get('topics'):
                f.write("## ğŸ“š ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯\n\n")
                for topic in analysis_data['topics'][:5]:
                    f.write(f"### {topic.get('topic', '')}\n")
                    f.write(f"{topic.get('description', '')}\n\n")

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
            if screenshots:
                f.write("## ğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ\n\n")
                for screenshot in screenshots:
                    f.write(f"### {screenshot['timestamp_formatted']}\n")
                    f.write(f"![Screenshot {screenshot['index']}]({screenshot['relative_path']})\n")
                    if screenshot.get('segment_text'):
                        f.write(f"\n**è©²å½“ç®‡æ‰€ã®ãƒ†ã‚­ã‚¹ãƒˆ:**\n")
                        f.write(f"> {screenshot['segment_text']}\n")
                    f.write("\n")

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            if analysis_data and analysis_data.get('keywords'):
                f.write("## ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n\n")
                keywords = analysis_data['keywords'][:20]
                f.write(", ".join(f"`{kw}`" for kw in keywords))
                f.write("\n\n")

            # æ„Ÿæƒ…åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
            if analysis_data and analysis_data.get('sentiment'):
                sentiment = analysis_data['sentiment']
                f.write("## ğŸ˜Š æ„Ÿæƒ…åˆ†æ\n\n")
                f.write(f"- **å…¨ä½“çš„ãªæ„Ÿæƒ…**: {sentiment.get('overall', 'neutral')}\n")
                f.write(f"- **ä¿¡é ¼åº¦**: {sentiment.get('confidence', 0.0):.1%}\n")
                if sentiment.get('emotions'):
                    f.write(f"- **æ¤œå‡ºã•ã‚ŒãŸæ„Ÿæƒ…**: {', '.join(sentiment['emotions'])}\n")
                f.write("\n")

            # éšå±¤çš„åˆ†æãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            if analysis_data and analysis_data.get('metadata') and analysis_data.get('hierarchical_summaries'):
                metadata = analysis_data['metadata']
                f.write("## ğŸ“Š éšå±¤çš„åˆ†æçµ±è¨ˆ\n\n")
                f.write(f"- **å‡¦ç†æ™‚é–“**: {metadata.get('processing_time', 0):.1f}ç§’\n")
                f.write(f"- **ç·ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°**: {metadata.get('total_segments', 0)}å€‹\n")
                f.write(f"- **éšå±¤æ•°**: {metadata.get('hierarchy_levels', 3)}å±¤\n")
                f.write(f"- **åœ§ç¸®é”æˆç‡**: {metadata.get('reduction_achieved', 0):.1%}\n")
                if metadata.get('level_stats'):
                    f.write("- **å„å±¤ã®çµ±è¨ˆ**:\n")
                    for level, stats in metadata.get('level_stats', {}).items():
                        f.write(f"  - {level}: {stats.get('count', 0)}å€‹ã®è¦ç´„\n")
                f.write("\n")

            # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if analysis_data and analysis_data.get('quality_metrics'):
                metrics = analysis_data['quality_metrics']
                f.write("## ğŸ“ˆ å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹\n\n")
                f.write(f"- **å¹³å‡ä¿¡é ¼åº¦**: {metrics.get('average_confidence', 0.0):.1%}\n")

                if 'confidence_distribution' in metrics:
                    dist = metrics['confidence_distribution']
                    f.write("- **ä¿¡é ¼åº¦åˆ†å¸ƒ**:\n")
                    f.write(f"  - é«˜ (80%ä»¥ä¸Š): {dist.get('high', 0)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ\n")
                    f.write(f"  - ä¸­ (50-80%): {dist.get('medium', 0)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ\n")
                    f.write(f"  - ä½ (50%æœªæº€): {dist.get('low', 0)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ\n")

                if 'text_metrics' in metrics:
                    text_metrics = metrics['text_metrics']
                    f.write(f"- **ç·å˜èªæ•°**: {text_metrics.get('total_words', 0):,}èª\n")
                    f.write(f"- **ç·æ–‡å­—æ•°**: {text_metrics.get('total_characters', 0):,}æ–‡å­—\n")

                f.write("\n")

            # æ¨å¥¨äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            if analysis_data and analysis_data.get('recommendations'):
                f.write("## ğŸ’¡ æ¨å¥¨äº‹é …\n\n")
                for i, rec in enumerate(analysis_data['recommendations'], 1):
                    f.write(f"{i}. {rec}\n")
                f.write("\n")

            # å®Œå…¨ãªæ–‡å­—èµ·ã“ã—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            if transcript_data and transcript_data.get('text'):
                f.write("## ğŸ“„ å®Œå…¨ãªæ–‡å­—èµ·ã“ã—\n\n")
                if transcript_data.get('segments'):
                    for segment in transcript_data['segments']:
                        start_time = format_duration(segment.get('start', 0))
                        end_time = format_duration(segment.get('end', 0))
                        text = segment.get('text', '').strip()
                        f.write(f"**[{start_time} - {end_time}]** {text}\n\n")
                else:
                    f.write(transcript_data['text'])
                    f.write("\n\n")

            # ãƒ•ãƒƒã‚¿ãƒ¼
            f.write("---\n")
            f.write("*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ VideoTranscriptAnalyzer ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*\n")

        self.logger.info(f"Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
        return report_path

    def _generate_html_report(self,
                            transcript_data: Optional[Dict[str, Any]],
                            analysis_data: Optional[Dict[str, Any]],
                            screenshots: List[Dict[str, Any]],
                            output_dir: Path) -> Path:
        """
        HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            transcript_data: æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿
            analysis_data: åˆ†æãƒ‡ãƒ¼ã‚¿
            screenshots: ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæƒ…å ±
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸHTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        report_path = output_dir / "video_analysis_report.html"

        # åŸºæœ¬çš„ãªHTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        html_content = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å‹•ç”»åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 40px; line-height: 1.6; }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; }}
        .section {{ margin: 20px 0; padding: 15px; border-left: 4px solid #667eea; }}
        .screenshot {{ max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 5px; }}
        .timestamp {{ color: #666; font-weight: bold; }}
        .keyword {{ background: #f0f0f0; padding: 2px 6px; border-radius: 3px; margin: 2px; display: inline-block; }}
        .confidence-high {{ color: #28a745; }}
        .confidence-medium {{ color: #ffc107; }}
        .confidence-low {{ color: #dc3545; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“¹ å‹•ç”»åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
        <p>ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</p>
    </div>
"""

        # æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if transcript_data or analysis_data:
            html_content += '<div class="section"><h2>ğŸ“Š æ¦‚è¦</h2><ul>'

            if transcript_data:
                duration = transcript_data.get('duration', 0)
                segments_count = len(transcript_data.get('segments', []))
                html_content += f'<li><strong>å‹•ç”»æ™‚é–“:</strong> {format_duration(duration)}</li>'
                html_content += f'<li><strong>ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°:</strong> {segments_count:,}å€‹</li>'
                html_content += f'<li><strong>æ¤œå‡ºè¨€èª:</strong> {transcript_data.get("language", "ä¸æ˜")}</li>'

            html_content += f'<li><strong>ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ•°:</strong> {len(screenshots)}æš</li>'
            html_content += '</ul></div>'

        # éšå±¤çš„è¦ç´„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if analysis_data and analysis_data.get('hierarchical_summaries'):
            hierarchical = analysis_data['hierarchical_summaries']

            # Level 3 - æœ€çµ‚çµ±åˆè¦ç´„
            if hierarchical.get('level3'):
                html_content += f'<div class="section"><h2>ğŸ“ çµ±åˆè¦ç´„</h2><p>{hierarchical["level3"].get("text", "")}</p></div>'

            # Level 2 - ä¸­é–“è¦ç´„
            if hierarchical.get('level2'):
                html_content += '<div class="section"><h2>ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦ç´„</h2>'
                for summary in hierarchical['level2'][:5]:
                    html_content += f'<h3>ã‚°ãƒ«ãƒ¼ãƒ— {summary.get("group_id", 0) + 1}</h3>'
                    html_content += f'<p class="timestamp">æ™‚é–“ç¯„å›²: {format_duration(summary.get("start_time", 0))} - {format_duration(summary.get("end_time", 0))}</p>'
                    html_content += f'<p>{summary.get("text", "")}</p>'
                html_content += '</div>'

            # é‡è¦ãªç¬é–“
            if analysis_data.get('key_moments'):
                html_content += '<div class="section"><h2>ğŸŒŸ é‡è¦ãªç¬é–“</h2><ul>'
                for moment in analysis_data['key_moments'][:10]:
                    importance = moment.get('importance_score', 0)
                    importance_class = 'confidence-high' if importance > 0.8 else 'confidence-medium' if importance > 0.5 else 'confidence-low'
                    html_content += f'<li><span class="{importance_class}">[{format_duration(moment.get("start_time", 0))}] (é‡è¦åº¦: {importance:.1%})</span><br>'
                    html_content += f'{moment.get("preview", "")}<br>'
                    html_content += f'<em>ç†ç”±: {moment.get("reason", "")}</em></li>'
                html_content += '</ul></div>'

        # é€šå¸¸ã®è¦ç´„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆéšå±¤çš„è¦ç´„ãŒãªã„å ´åˆï¼‰
        elif analysis_data and analysis_data.get('summary'):
            summary = analysis_data['summary'].get('main_summary', '')
            html_content += f'<div class="section"><h2>ğŸ“ è¦ç´„</h2><p>{summary}</p></div>'

        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if screenshots:
            html_content += '<div class="section"><h2>ğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ</h2>'
            for screenshot in screenshots:
                html_content += f'<h3 class="timestamp">{screenshot["timestamp_formatted"]}</h3>'
                html_content += f'<img src="{screenshot["relative_path"]}" alt="Screenshot {screenshot["index"]}" class="screenshot"><br>'
                if screenshot.get('segment_text'):
                    html_content += f'<blockquote>{screenshot["segment_text"]}</blockquote>'
            html_content += '</div>'

        html_content += '</body></html>'

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        self.logger.info(f"HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
        return report_path