# VideoTranscriptAnalyzer 環境変数設定ファイル例
# このファイルを .env にコピーして必要な値を設定してください
# cp .env.example .env

# ============================================
# OpenAI API設定
# ============================================
# AI分析機能（GPT-4による要約、分析）を使用する場合に必要
# OpenAI APIキーの取得: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ============================================
# OpenAI互換API設定（オプション）
# ============================================
# カスタムAPIエンドポイント（未設定の場合はOpenAI標準を使用）
# LM Studio: http://localhost:1234/v1
# Ollama: http://localhost:11434/v1
# Azure OpenAI: https://YOUR_RESOURCE.openai.azure.com/
# Groq: https://api.groq.com/openai/v1
# Together AI: https://api.together.xyz/v1
# OPENAI_API_BASE_URL=http://localhost:1234/v1

# APIタイプ（オプション: azure, custom）
# OPENAI_API_TYPE=custom

# モデル名のオーバーライド（オプション）
# OPENAI_MODEL=gpt-4-turbo-preview

# ============================================
# その他のオプション設定
# ============================================
# デフォルトの出力ディレクトリ（未設定の場合: ./output）
# OUTPUT_DIR=/path/to/output

# デフォルトの作業ディレクトリ
# WORK_DIR=/tmp/video_transcript_analyzer

# ログレベル（DEBUG, INFO, WARNING, ERROR, CRITICAL）
# LOG_LEVEL=INFO

# Whisperモデルのキャッシュディレクトリ
# WHISPER_CACHE_DIR=~/.cache/whisper

# CUDAデバイスID（複数GPUの場合）
# CUDA_VISIBLE_DEVICES=0

# 並列処理の最大ワーカー数
# MAX_WORKERS=4

# ============================================
# プロキシ設定（企業環境等で必要な場合）
# ============================================
# HTTP_PROXY=http://proxy.example.com:8080
# HTTPS_PROXY=http://proxy.example.com:8080
# NO_PROXY=localhost,127.0.0.1