#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Whisper Transcript to Professional Report Processor
Based on CLAUDE.md specifications
"""

import os
import json
import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple

# Add project root to path
sys.path.append(str(Path(__file__).parent))

from modules.gemini_ultimate_generator import GeminiUltimateGenerator
from modules.reporter import Reporter
from modules.keyword_analyzer import KeywordAnalyzer
from modules.utils import setup_logging, extract_video_frame

# Setup logging
logger = setup_logging(__name__)

class TranscriptReportGenerator:
    """CLAUDE.mdä»•æ§˜ã«åŸºã¥ããƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨"""

    def __init__(self, gemini_api_key: str = None):
        """åˆæœŸåŒ–"""
        self.gemini = GeminiUltimateGenerator(api_key=gemini_api_key)
        self.keyword_analyzer = KeywordAnalyzer()
        self.reporter = Reporter()

        # Screenshot trigger weights
        self.screenshot_triggers = {
            "speaker_introduction": 0.9,
            "shocking_statistic": 1.0,
            "visual_demonstration": 0.95,
            "graph_or_chart_mention": 1.0,
            "before_after_comparison": 0.95,
            "success_story_peak": 0.85,
            "key_formula_or_method": 1.0,
            "emotional_moment": 0.8,
            "final_summary": 0.9
        }

        # Topic patterns
        self.topic_patterns = {
            "revenue_model": ["åç›Š", "ãƒãƒã‚¿ã‚¤ã‚º", "å£²ä¸Š", "åå…¥", "åˆ©ç›Š"],
            "growth_strategy": ["æˆé•·", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼", "ãƒªãƒ¼ãƒ", "æ‹¡å¤§", "ä¼¸ã³"],
            "content_creation": ["ã‚³ãƒ³ãƒ†ãƒ³ãƒ„", "æŠ•ç¨¿", "ãƒªãƒ¼ãƒ«", "å‹•ç”»", "ä½œæˆ"],
            "case_study": ["äº‹ä¾‹", "æˆåŠŸä¾‹", "å®Ÿç¸¾", "çµæœ", "å®Ÿç¾"],
            "technical_tutorial": ["æ–¹æ³•", "ã‚„ã‚Šæ–¹", "ã‚¹ãƒ†ãƒƒãƒ—", "æ‰‹é †", "ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯"],
            "mindset": ["è€ƒãˆæ–¹", "ãƒã‚¤ãƒ³ãƒ‰", "å“²å­¦", "æ„è­˜", "å§¿å‹¢"],
            "tools_resources": ["ãƒ„ãƒ¼ãƒ«", "ãƒªã‚½ãƒ¼ã‚¹", "ä½¿ã„æ–¹", "æ´»ç”¨", "æ©Ÿèƒ½"]
        }

    def load_transcript(self, transcript_path: str) -> Dict:
        """Whisper JSONãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        logger.info(f"Loading transcript: {transcript_path}")
        with open(transcript_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def analyze_segments(self, segments: List[Dict]) -> Dict:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã—ã¦ã‚­ãƒ¼ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã‚’ç‰¹å®š"""
        logger.info("Analyzing segments for key moments...")

        analysis = {
            "topics": [],
            "key_moments": [],
            "statistics": [],
            "action_items": [],
            "case_studies": []
        }

        for i, segment in enumerate(segments):
            text = segment.get('text', '')
            timestamp = segment.get('start', 0)

            # Topic detection
            for topic, keywords in self.topic_patterns.items():
                if any(kw in text for kw in keywords):
                    analysis["topics"].append({
                        "topic": topic,
                        "text": text,
                        "timestamp": timestamp,
                        "index": i
                    })

            # Statistics detection
            import re
            numbers = re.findall(r'\d+[ä¸‡å„„åƒç™¾]?[å††äººå€‹]', text)
            if numbers:
                analysis["statistics"].append({
                    "numbers": numbers,
                    "text": text,
                    "timestamp": timestamp,
                    "index": i
                })

            # Action items detection
            action_keywords = ["ã‚¹ãƒ†ãƒƒãƒ—", "æ–¹æ³•", "ã‚„ã‚Šæ–¹", "ã¾ãš", "æ¬¡ã«", "æœ€å¾Œã«"]
            if any(kw in text for kw in action_keywords):
                analysis["action_items"].append({
                    "text": text,
                    "timestamp": timestamp,
                    "index": i
                })

        return analysis

    def select_screenshot_moments(self, analysis: Dict, max_screenshots: int = 10) -> List[Dict]:
        """ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ’®å½±ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’é¸å®š"""
        logger.info(f"Selecting top {max_screenshots} screenshot moments...")

        screenshot_moments = []

        # Opening scene (first meaningful segment)
        if analysis["topics"]:
            screenshot_moments.append({
                "name": "opening_scene",
                "timestamp": 5.0,  # 5 seconds in
                "weight": 0.9
            })

        # Key statistics
        for stat in analysis["statistics"][:3]:  # Top 3 statistics
            screenshot_moments.append({
                "name": f"statistic_{stat['index']}",
                "timestamp": stat["timestamp"],
                "weight": 1.0
            })

        # Important topics
        seen_topics = set()
        for topic_entry in analysis["topics"]:
            topic = topic_entry["topic"]
            if topic not in seen_topics and len(screenshot_moments) < max_screenshots:
                screenshot_moments.append({
                    "name": f"{topic}_{topic_entry['index']}",
                    "timestamp": topic_entry["timestamp"],
                    "weight": 0.85
                })
                seen_topics.add(topic)

        # Sort by timestamp and limit
        screenshot_moments.sort(key=lambda x: x["timestamp"])
        return screenshot_moments[:max_screenshots]

    def generate_markdown_report(self, transcript_data: Dict, analysis: Dict,
                                screenshots: List[Dict], output_path: str) -> str:
        """ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        logger.info("Generating markdown report...")

        # Use Gemini for high-quality summary
        all_text = " ".join([s.get('text', '') for s in transcript_data.get('segments', [])])

        # Generate comprehensive summary
        summary_prompt = f"""
        ä»¥ä¸‹ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

        {all_text[:50000]}  # Limit for API

        ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
        1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆæ ¸å¿ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
        2. ä¸»è¦ãƒã‚¤ãƒ³ãƒˆï¼ˆ3-5å€‹ï¼‰
        3. å…·ä½“çš„ãªæ•°å€¤ã‚„å®Ÿç¸¾
        4. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆåˆç´šãƒ»ä¸­ç´šãƒ»ä¸Šç´šåˆ¥ï¼‰
        5. ã¾ã¨ã‚
        """

        summary = self.gemini.generate(summary_prompt)

        # Build report structure
        report_lines = [
            f"# ğŸ“ {Path(output_path).stem.replace('_', ' ').title()} å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆ",
            "",
            "## ğŸ¯ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼",
            "",
            summary.get("executive_summary", ""),
            "",
            "### ğŸ“Œ æœ€é‡è¦ãƒã‚¤ãƒ³ãƒˆ",
            f"> {summary.get('key_point', '')}",
            "",
            "---",
            ""
        ]

        # Add main content sections
        if analysis["statistics"]:
            report_lines.extend([
                "## ğŸ’° é‡è¦ãªæ•°å€¤ãƒ»å®Ÿç¸¾",
                "",
            ])
            for stat in analysis["statistics"][:5]:
                report_lines.append(f"- {stat['text']}")
            report_lines.extend(["", "---", ""])

        # Add action items
        if analysis["action_items"]:
            report_lines.extend([
                "## âœ… å®Ÿè·µã™ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
                "",
                "### åˆå¿ƒè€…å‘ã‘",
            ])
            for item in analysis["action_items"][:3]:
                report_lines.append(f"1. {item['text'][:100]}...")
            report_lines.extend(["", "---", ""])

        # Add metadata
        report_lines.extend([
            "## ğŸ“š å‚è€ƒæƒ…å ±",
            f"- **å‡¦ç†æ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}",
            f"- **ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°**: {len(transcript_data.get('segments', []))}",
            f"- **ç·æ™‚é–“**: {transcript_data.get('segments', [{}])[-1].get('end', 0):.1f}ç§’",
            "",
            "---",
            "",
            "*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯CLAUDE.mdä»•æ§˜ã«åŸºã¥ã„ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*"
        ])

        return "\n".join(report_lines)

    def process(self, transcript_path: str, output_dir: str,
                video_path: str = None, max_screenshots: int = 10):
        """å®Œå…¨ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼"""
        logger.info("Starting transcript processing...")

        # Create output directories
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        screenshots_dir = output_dir / "screenshots"
        screenshots_dir.mkdir(exist_ok=True)

        # Load and analyze transcript
        transcript_data = self.load_transcript(transcript_path)
        segments = transcript_data.get('segments', [])

        analysis = self.analyze_segments(segments)

        # Select screenshot moments
        screenshot_moments = self.select_screenshot_moments(analysis, max_screenshots)

        # Extract screenshots if video provided
        if video_path and Path(video_path).exists():
            logger.info("Extracting screenshots...")
            for moment in screenshot_moments:
                screenshot_path = screenshots_dir / f"{moment['name']}.jpg"
                try:
                    extract_video_frame(
                        video_path,
                        moment['timestamp'],
                        str(screenshot_path)
                    )
                    logger.info(f"Extracted: {screenshot_path.name}")
                except Exception as e:
                    logger.warning(f"Failed to extract {moment['name']}: {e}")

        # Generate report
        report_path = output_dir / f"{Path(transcript_path).stem}_report.md"
        report_content = self.generate_markdown_report(
            transcript_data, analysis, screenshot_moments, str(report_path)
        )

        # Save report
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        logger.info(f"âœ… Report generated: {report_path}")
        logger.info(f"ğŸ“¸ Screenshots: {len(screenshot_moments)} moments identified")

        return {
            "report_path": str(report_path),
            "screenshots": len(screenshot_moments),
            "topics": len(set([t["topic"] for t in analysis["topics"]])),
            "statistics": len(analysis["statistics"]),
            "action_items": len(analysis["action_items"])
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Whisper Transcript to Professional Report Generator"
    )
    parser.add_argument(
        "--input", "-i",
        required=True,
        help="Path to Whisper JSON transcript file"
    )
    parser.add_argument(
        "--output", "-o",
        default="output/reports",
        help="Output directory for report and screenshots"
    )
    parser.add_argument(
        "--video", "-v",
        help="Path to video file for screenshot extraction"
    )
    parser.add_argument(
        "--screenshots", "-s",
        type=int,
        default=10,
        help="Maximum number of screenshots to extract"
    )
    parser.add_argument(
        "--gemini-api-key",
        help="Gemini API key (or set in config.yaml)"
    )

    args = parser.parse_args()

    # Initialize generator
    generator = TranscriptReportGenerator(
        gemini_api_key=args.gemini_api_key
    )

    # Process transcript
    result = generator.process(
        transcript_path=args.input,
        output_dir=args.output,
        video_path=args.video,
        max_screenshots=args.screenshots
    )

    # Print results
    print("\n" + "="*70)
    print("âœ… TRANSCRIPT PROCESSING COMPLETE")
    print("="*70)
    print(f"ğŸ“ Report: {result['report_path']}")
    print(f"ğŸ“¸ Screenshots: {result['screenshots']}")
    print(f"ğŸ“Š Topics: {result['topics']}")
    print(f"ğŸ’° Statistics: {result['statistics']}")
    print(f"âœ… Action Items: {result['action_items']}")
    print("="*70)


if __name__ == "__main__":
    main()